# AMCresultsAnalysis

**AMCresultsAnalysis** is a Python application designed to process the results of exams generated by AMC (Auto-Multiple-Choice). It analyzes the overall results and provides detailed information on each question, giving valuable insights for reviewing and improving the quality of assessments.

## Features

- **Comprehensive Exam Analysis**: Analyzes exam results using Classical Test Theory (CTT) metrics including difficulty, discrimination, and item-total correlation
- **Automated Report Generation**: Creates detailed PDF reports with charts and visualizations
- **Historical Tracking**: Store exam metrics over time in Airtable or Baserow for comparative analysis
- **AI-Powered Insights**: Optional Claude AI integration for intelligent analysis and recommendations
- **Type-Safe Configuration**: Pydantic-based settings validation with environment variable support
- **Robust Test Suite**: 358 comprehensive tests with 96.17% code coverage
- **Production Ready**: Extensively tested with both unit tests and integration tests

## Installation

1. Clone the repository to your local machine using the following command:

   ```bash
   git clone https://github.com/your-username/AMCresultsAnalysis.git
   ```

2. Navigate to the project directory:

   ```bash
   cd AMCresultsAnalysis
   ```

3. Create a `.env` file in the project directory to customize the application according to your needs. This file uses environment variables with Pydantic validation for type-safe configuration.

   ```bash
   # Example .env file

   # Path to your AMC Projects Directory (required)
   AMC_PROJECTS_DIR=/Users/greg/Dropbox/01-QCM/_AMC/Projets-QCM

   # Number of students below which discrimination indices are not calculated (default: 99)
   AMC_STUDENT_THRESHOLD=90

   # Company information for PDF reports
   AMC_COMPANY_NAME=Print&Scan
   AMC_COMPANY_URL=www.printandscan.fr

   # Optional: Claude AI API key for intelligent analysis
   AMC_CLAUDE_API_KEY=your_api_key_here
   AMC_ENABLE_AI_ANALYSIS=true

   # Optional: Exam Repository for historical tracking (see EXAM_REPOSITORY.md)
   AMC_REPOSITORY_BACKEND=airtable  # Options: 'airtable', 'baserow', or 'none'
   AIRTABLE_API_KEY=your_airtable_api_key_here
   AIRTABLE_BASE_ID=your_base_id_here
   ```

   **Configuration Options:**
   - `AMC_PROJECTS_DIR`: Path where your AMC projects are located (required)
   - `AMC_STUDENT_THRESHOLD`: Minimum students needed for discrimination analysis (default: 99)
   - `AMC_COMPANY_NAME`: Your organization name for PDF reports
   - `AMC_COMPANY_URL`: Your organization URL for PDF reports
   - `AMC_CLAUDE_API_KEY`: (Optional) Your Claude/Anthropic API key for AI-powered insights
   - `AMC_ENABLE_AI_ANALYSIS`: (Optional) Enable/disable AI analysis (default: false)
   - `AMC_REPOSITORY_BACKEND`: (Optional) Store metrics in 'airtable', 'baserow', or 'none' (default: 'none')
   - `AIRTABLE_API_KEY`: (Optional) Your Airtable API key for exam tracking
   - `AIRTABLE_BASE_ID`: (Optional) Your Airtable Base ID

   ðŸ“Š **New: Exam Repository** - Track exam metrics over time! See [EXAM_REPOSITORY.md](EXAM_REPOSITORY.md) for complete setup guide.

4. Install the required dependencies by running the following command:

   ```bash
   pip install -r requirements.txt
   ```
   
   If you prefer to create a virtual environment for this project, you can do so by following these steps:

   - Create a virtual environment:

     ```bash
     python -m venv env
     ```

   - Activate the virtual environment:

     - For Windows:

       ```bash
       .\env\Scripts\activate
       ```

     - For macOS/Linux:

       ```bash
       source env/bin/activate
       ```

   - Install the required dependencies:

     ```bash
     pip install -r requirements.txt
     ```

   By using a virtual environment, you can keep the project dependencies isolated from your system's Python environment.

5. You are now ready to use the **AMCresultsAnalysis** application as described in the "Usage" section.

## Usage

1. Launch the application by running the following command:

   ```bash
   python amcreport.py
   ```

2. The application will display a list of projects found in the specified projects directory. Select the desired project by entering the corresponding number.

3. The application will process the results of the selected project, generate a PDF report with charts, and save it in the project directory.

4. Once the report is generated, it will be opened using the default system PDF viewer.

## Testing

This project includes a comprehensive test suite with excellent code coverage.

### Test Suite Statistics

- **Total Tests:** 358 tests (357 passing, 1 skipped)
- **Code Coverage:** 96.17%
- **Test Success Rate:** 100%
- **Framework:** pytest 8.4+
- **Execution Time:** ~2 minutes (full suite)

### Test Categories

1. **Unit Tests** (338 tests): Fast, isolated tests of individual functions using mocks
2. **Integration Tests** (20 tests): Complete workflow validation with real exam data
3. **Edge Case Tests** (6 tests): Coverage of error paths and rare scenarios

### Running Tests

```bash
# Run all tests
pytest -v

# Run with coverage report
pytest --cov --cov-report=html --cov-report=term

# Run only unit tests (fast)
pytest -m "not integration"

# Run only integration tests
pytest -m integration
```

For complete testing documentation, see [TESTING.md](TESTING.md).

### Platform Compatibility

This project has been tested on:
- **macOS**: Full compatibility
- **Linux**: Full compatibility
- **Windows**: May require additional testing 

## Troubleshooting

If you encounter any issues during the installation or usage of the application, please try the following troubleshooting steps:

1. Make sure you have Python 3.x installed on your machine. You can check the installed version by running the following command:

   ```bash
   python --version
   ```

   If Python is not installed or you have an older version, please install or update Python accordingly.

2. Verify that you have the necessary permissions to clone the repository and install the dependencies.

3. If you encounter errors related to missing packages or dependencies, ensure that you have installed them correctly by following the instructions in the "Installation" section.

4. Double-check the settings in the `.env` file and ensure that the paths and configurations are correct for your environment. Verify that `AMC_PROJECTS_DIR` points to the correct directory.

5. If you are experiencing issues with the Claude AI integration, ensure that you have:
   - A valid Anthropic API key set in `AMC_CLAUDE_API_KEY`
   - AI analysis enabled with `AMC_ENABLE_AI_ANALYSIS=true`
   - An active internet connection for API calls

6. For configuration validation errors, check that:
   - Your `.env` file uses the correct variable names (all start with `AMC_`)
   - Paths use absolute paths or correct relative paths
   - Numeric values (like `AMC_STUDENT_THRESHOLD`) are valid integers

If the above steps do not resolve your issue, please open an issue on the project repository on GitHub, providing detailed information about the problem you encountered, including any error messages or logs.

## License

This project is licensed under the [MIT License](LICENSE).

## Contributing

Contributions are welcome! If you have any suggestions, bug reports, or feature requests, please open an issue or submit a pull request.

## Acknowledgements

The **AMCresultsAnalysis** application is built upon the hard work and contributions of many individuals and open-source projects. We would like to express our gratitude to the following:

- The developers of [Auto-Multiple-Choice](https://www.auto-multiple-choice.net/) for providing a powerful tool for creating and grading multiple-choice exams
- The creators of [matplotlib](https://matplotlib.org/) for their comprehensive library that enables the creation of stunning visualizations in Python
- The [pandas](https://pandas.pydata.org/) team for their powerful data analysis library
- The contributors to [Anthropic's Claude AI](https://www.anthropic.com/) for providing intelligent analysis capabilities
- The maintainers of [Pydantic](https://docs.pydantic.dev/) for their excellent data validation library
- The [fpdf2](https://github.com/py-pdf/fpdf2) team for their modern PDF generation library
- The [pytest](https://pytest.org/) community for their outstanding testing framework
- The amazing [Codeium](https://codeium.com/) extension and [Claude Code](https://claude.com/claude-code) that helped accelerate development

We extend our thanks to the entire open-source community for their continuous efforts in creating and maintaining these invaluable resources.

## Disclaimer

This application is provided as-is without any warranty. Use it at your own risk.

Please note that the optional use of Claude AI may require:
- A valid Anthropic API key
- Compliance with Anthropic's usage policy and terms of service
- API usage costs based on your Anthropic pricing plan

The AI analysis feature is completely optional and the application works fully without it.

---
**Note:** Ensure that you have the necessary permissions and dependencies in place before using this application. For more detailed instructions and troubleshooting, refer to the project's documentation or the project repository on GitHub.

